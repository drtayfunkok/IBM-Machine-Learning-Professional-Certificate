{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>90</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.294</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.699</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.356</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>62</td>\n",
       "      <td>32</td>\n",
       "      <td>126</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "      <td>228</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.255</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "160               4                     151              90              38   \n",
       "593               2                      82              52              22   \n",
       "98                6                      93              50              30   \n",
       "567               6                      92              62              32   \n",
       "95                6                     144              72              27   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "160        0  29.7              0.294   36             0  \n",
       "593      115  28.5              1.699   25             0  \n",
       "98        64  28.7              0.356   23             0  \n",
       "567      126  32.0              0.085   46             0  \n",
       "95       228  33.9              0.255   40             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.776\n",
      "roc-auc is 0.829\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9801 - accuracy: 0.3472 - val_loss: 0.9736 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9491 - accuracy: 0.3490 - val_loss: 0.9448 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9208 - accuracy: 0.3507 - val_loss: 0.9184 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.3507 - val_loss: 0.8945 - val_accuracy: 0.3542\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.3524 - val_loss: 0.8727 - val_accuracy: 0.3490\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.3611 - val_loss: 0.8528 - val_accuracy: 0.3385\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.3663 - val_loss: 0.8349 - val_accuracy: 0.3125\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8127 - accuracy: 0.3698 - val_loss: 0.8185 - val_accuracy: 0.3073\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7967 - accuracy: 0.3681 - val_loss: 0.8038 - val_accuracy: 0.3125\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7821 - accuracy: 0.3733 - val_loss: 0.7904 - val_accuracy: 0.3229\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7689 - accuracy: 0.3837 - val_loss: 0.7782 - val_accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7570 - accuracy: 0.3976 - val_loss: 0.7673 - val_accuracy: 0.3333\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7462 - accuracy: 0.4062 - val_loss: 0.7573 - val_accuracy: 0.3281\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7363 - accuracy: 0.4201 - val_loss: 0.7484 - val_accuracy: 0.3542\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.4375 - val_loss: 0.7402 - val_accuracy: 0.3958\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7194 - accuracy: 0.4566 - val_loss: 0.7328 - val_accuracy: 0.4427\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.4826 - val_loss: 0.7262 - val_accuracy: 0.4583\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.4931 - val_loss: 0.7201 - val_accuracy: 0.4844\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.5226 - val_loss: 0.7145 - val_accuracy: 0.4948\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5312 - val_loss: 0.7095 - val_accuracy: 0.5312\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5451 - val_loss: 0.7049 - val_accuracy: 0.5625\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5503 - val_loss: 0.7007 - val_accuracy: 0.5625\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5625 - val_loss: 0.6969 - val_accuracy: 0.5729\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5642 - val_loss: 0.6934 - val_accuracy: 0.5729\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.5781 - val_loss: 0.6902 - val_accuracy: 0.5990\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.5868 - val_loss: 0.6872 - val_accuracy: 0.6094\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.5938 - val_loss: 0.6845 - val_accuracy: 0.6146\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6111 - val_loss: 0.6820 - val_accuracy: 0.6198\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6111 - val_loss: 0.6796 - val_accuracy: 0.6250\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6146 - val_loss: 0.6775 - val_accuracy: 0.6302\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6250 - val_loss: 0.6755 - val_accuracy: 0.6458\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6285 - val_loss: 0.6736 - val_accuracy: 0.6458\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6526 - accuracy: 0.6372 - val_loss: 0.6718 - val_accuracy: 0.6354\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6406 - val_loss: 0.6702 - val_accuracy: 0.6406\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6441 - val_loss: 0.6686 - val_accuracy: 0.6406\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6424 - val_loss: 0.6672 - val_accuracy: 0.6458\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6441 - val_loss: 0.6658 - val_accuracy: 0.6458\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6476 - val_loss: 0.6645 - val_accuracy: 0.6458\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6493 - val_loss: 0.6632 - val_accuracy: 0.6510\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.6510 - val_loss: 0.6620 - val_accuracy: 0.6615\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6580 - val_loss: 0.6609 - val_accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6580 - val_loss: 0.6598 - val_accuracy: 0.6562\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6632 - val_loss: 0.6588 - val_accuracy: 0.6562\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6615 - val_loss: 0.6578 - val_accuracy: 0.6562\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6649 - val_loss: 0.6568 - val_accuracy: 0.6562\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6667 - val_loss: 0.6559 - val_accuracy: 0.6562\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6701 - val_loss: 0.6549 - val_accuracy: 0.6562\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6719 - val_loss: 0.6541 - val_accuracy: 0.6562\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6701 - val_loss: 0.6532 - val_accuracy: 0.6510\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6684 - val_loss: 0.6524 - val_accuracy: 0.6510\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6736 - val_loss: 0.6516 - val_accuracy: 0.6510\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6753 - val_loss: 0.6508 - val_accuracy: 0.6510\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6771 - val_loss: 0.6500 - val_accuracy: 0.6562\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6788 - val_loss: 0.6492 - val_accuracy: 0.6562\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6806 - val_loss: 0.6484 - val_accuracy: 0.6510\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6771 - val_loss: 0.6477 - val_accuracy: 0.6510\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6788 - val_loss: 0.6470 - val_accuracy: 0.6510\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6788 - val_loss: 0.6462 - val_accuracy: 0.6510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.6788 - val_loss: 0.6455 - val_accuracy: 0.6562\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6788 - val_loss: 0.6448 - val_accuracy: 0.6562\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6753 - val_loss: 0.6441 - val_accuracy: 0.6562\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6753 - val_loss: 0.6435 - val_accuracy: 0.6510\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6771 - val_loss: 0.6428 - val_accuracy: 0.6510\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6771 - val_loss: 0.6421 - val_accuracy: 0.6510\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6753 - val_loss: 0.6414 - val_accuracy: 0.6562\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6753 - val_loss: 0.6408 - val_accuracy: 0.6562\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6753 - val_loss: 0.6401 - val_accuracy: 0.6562\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6753 - val_loss: 0.6395 - val_accuracy: 0.6562\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6788 - val_loss: 0.6388 - val_accuracy: 0.6562\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6788 - val_loss: 0.6382 - val_accuracy: 0.6562\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6771 - val_loss: 0.6376 - val_accuracy: 0.6562\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6771 - val_loss: 0.6369 - val_accuracy: 0.6562\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6771 - val_loss: 0.6363 - val_accuracy: 0.6562\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6771 - val_loss: 0.6357 - val_accuracy: 0.6562\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6788 - val_loss: 0.6351 - val_accuracy: 0.6562\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6771 - val_loss: 0.6345 - val_accuracy: 0.6562\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6771 - val_loss: 0.6338 - val_accuracy: 0.6562\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6771 - val_loss: 0.6332 - val_accuracy: 0.6562\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6788 - val_loss: 0.6326 - val_accuracy: 0.6510\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6788 - val_loss: 0.6320 - val_accuracy: 0.6510\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6788 - val_loss: 0.6314 - val_accuracy: 0.6510\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6788 - val_loss: 0.6308 - val_accuracy: 0.6510\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6788 - val_loss: 0.6302 - val_accuracy: 0.6510\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6788 - val_loss: 0.6297 - val_accuracy: 0.6510\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6788 - val_loss: 0.6291 - val_accuracy: 0.6510\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6788 - val_loss: 0.6285 - val_accuracy: 0.6510\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6788 - val_loss: 0.6279 - val_accuracy: 0.6510\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6788 - val_loss: 0.6273 - val_accuracy: 0.6510\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6788 - val_loss: 0.6267 - val_accuracy: 0.6510\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6788 - val_loss: 0.6262 - val_accuracy: 0.6510\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6788 - val_loss: 0.6256 - val_accuracy: 0.6562\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6788 - val_loss: 0.6250 - val_accuracy: 0.6562\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6788 - val_loss: 0.6244 - val_accuracy: 0.6562\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6788 - val_loss: 0.6239 - val_accuracy: 0.6562\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.6788 - val_loss: 0.6233 - val_accuracy: 0.6562\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6771 - val_loss: 0.6228 - val_accuracy: 0.6562\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6771 - val_loss: 0.6222 - val_accuracy: 0.6562\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6771 - val_loss: 0.6216 - val_accuracy: 0.6562\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6771 - val_loss: 0.6211 - val_accuracy: 0.6562\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6771 - val_loss: 0.6205 - val_accuracy: 0.6562\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6771 - val_loss: 0.6200 - val_accuracy: 0.6562\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6771 - val_loss: 0.6194 - val_accuracy: 0.6562\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6771 - val_loss: 0.6189 - val_accuracy: 0.6562\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6771 - val_loss: 0.6183 - val_accuracy: 0.6615\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6788 - val_loss: 0.6178 - val_accuracy: 0.6615\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6771 - val_loss: 0.6173 - val_accuracy: 0.6615\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6771 - val_loss: 0.6167 - val_accuracy: 0.6615\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6788 - val_loss: 0.6162 - val_accuracy: 0.6667\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6788 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6788 - val_loss: 0.6151 - val_accuracy: 0.6667\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6788 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6788 - val_loss: 0.6141 - val_accuracy: 0.6667\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6788 - val_loss: 0.6135 - val_accuracy: 0.6667\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6788 - val_loss: 0.6130 - val_accuracy: 0.6667\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6788 - val_loss: 0.6125 - val_accuracy: 0.6667\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6788 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6788 - val_loss: 0.6114 - val_accuracy: 0.6667\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6788 - val_loss: 0.6109 - val_accuracy: 0.6667\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6788 - val_loss: 0.6104 - val_accuracy: 0.6667\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6788 - val_loss: 0.6099 - val_accuracy: 0.6667\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6788 - val_loss: 0.6094 - val_accuracy: 0.6667\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6788 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6788 - val_loss: 0.6084 - val_accuracy: 0.6667\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6806 - val_loss: 0.6079 - val_accuracy: 0.6771\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6806 - val_loss: 0.6074 - val_accuracy: 0.6771\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6823 - val_loss: 0.6069 - val_accuracy: 0.6771\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.6806 - val_loss: 0.6064 - val_accuracy: 0.6771\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6806 - val_loss: 0.6059 - val_accuracy: 0.6771\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6806 - val_loss: 0.6054 - val_accuracy: 0.6771\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6806 - val_loss: 0.6049 - val_accuracy: 0.6771\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6806 - val_loss: 0.6044 - val_accuracy: 0.6823\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6806 - val_loss: 0.6039 - val_accuracy: 0.6823\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.6806 - val_loss: 0.6034 - val_accuracy: 0.6823\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6806 - val_loss: 0.6029 - val_accuracy: 0.6823\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6806 - val_loss: 0.6024 - val_accuracy: 0.6875\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6823 - val_loss: 0.6019 - val_accuracy: 0.6875\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6823 - val_loss: 0.6015 - val_accuracy: 0.6875\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.6823 - val_loss: 0.6010 - val_accuracy: 0.6875\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6823 - val_loss: 0.6005 - val_accuracy: 0.6875\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6823 - val_loss: 0.6000 - val_accuracy: 0.6875\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6840 - val_loss: 0.5995 - val_accuracy: 0.6875\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6840 - val_loss: 0.5991 - val_accuracy: 0.6875\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.6840 - val_loss: 0.5986 - val_accuracy: 0.6875\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6823 - val_loss: 0.5981 - val_accuracy: 0.6875\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6840 - val_loss: 0.5977 - val_accuracy: 0.6875\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.6858 - val_loss: 0.5972 - val_accuracy: 0.6875\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6858 - val_loss: 0.5967 - val_accuracy: 0.6823\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.6858 - val_loss: 0.5963 - val_accuracy: 0.6875\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6858 - val_loss: 0.5958 - val_accuracy: 0.6875\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.6858 - val_loss: 0.5953 - val_accuracy: 0.6927\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6875 - val_loss: 0.5949 - val_accuracy: 0.6927\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.6875 - val_loss: 0.5944 - val_accuracy: 0.6927\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.6875 - val_loss: 0.5940 - val_accuracy: 0.6927\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.6875 - val_loss: 0.5935 - val_accuracy: 0.6927\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6858 - val_loss: 0.5931 - val_accuracy: 0.6927\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.6858 - val_loss: 0.5926 - val_accuracy: 0.6927\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.6858 - val_loss: 0.5922 - val_accuracy: 0.6927\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.6892 - val_loss: 0.5917 - val_accuracy: 0.6927\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.6875 - val_loss: 0.5913 - val_accuracy: 0.6927\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6892 - val_loss: 0.5908 - val_accuracy: 0.6875\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.6892 - val_loss: 0.5904 - val_accuracy: 0.6875\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.6910 - val_loss: 0.5899 - val_accuracy: 0.6875\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6910 - val_loss: 0.5895 - val_accuracy: 0.6875\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6927 - val_loss: 0.5891 - val_accuracy: 0.6875\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.6944 - val_loss: 0.5886 - val_accuracy: 0.6823\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6944 - val_loss: 0.5882 - val_accuracy: 0.6823\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.6962 - val_loss: 0.5877 - val_accuracy: 0.6875\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.6944 - val_loss: 0.5873 - val_accuracy: 0.6927\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.6979 - val_loss: 0.5869 - val_accuracy: 0.6927\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6979 - val_loss: 0.5865 - val_accuracy: 0.6927\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.6997 - val_loss: 0.5860 - val_accuracy: 0.6927\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.6979 - val_loss: 0.5856 - val_accuracy: 0.6927\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6997 - val_loss: 0.5852 - val_accuracy: 0.6927\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.6997 - val_loss: 0.5848 - val_accuracy: 0.6927\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.6997 - val_loss: 0.5843 - val_accuracy: 0.6927\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.6997 - val_loss: 0.5839 - val_accuracy: 0.6927\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.6997 - val_loss: 0.5835 - val_accuracy: 0.6927\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.6979 - val_loss: 0.5831 - val_accuracy: 0.6927\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6979 - val_loss: 0.5827 - val_accuracy: 0.6927\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.6979 - val_loss: 0.5823 - val_accuracy: 0.6927\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6979 - val_loss: 0.5818 - val_accuracy: 0.6927\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.6979 - val_loss: 0.5814 - val_accuracy: 0.6927\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6979 - val_loss: 0.5810 - val_accuracy: 0.6979\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6979 - val_loss: 0.5806 - val_accuracy: 0.6979\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.6979 - val_loss: 0.5802 - val_accuracy: 0.6979\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.6979 - val_loss: 0.5798 - val_accuracy: 0.6979\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.6979 - val_loss: 0.5794 - val_accuracy: 0.6979\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.6979 - val_loss: 0.5790 - val_accuracy: 0.6979\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.6997 - val_loss: 0.5786 - val_accuracy: 0.6979\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6997 - val_loss: 0.5782 - val_accuracy: 0.6979\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7014 - val_loss: 0.5778 - val_accuracy: 0.7031\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7014 - val_loss: 0.5774 - val_accuracy: 0.7031\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7014 - val_loss: 0.5770 - val_accuracy: 0.7031\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.6997 - val_loss: 0.5766 - val_accuracy: 0.7031\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.6997 - val_loss: 0.5762 - val_accuracy: 0.7031\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.6979 - val_loss: 0.5758 - val_accuracy: 0.7031\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.6979 - val_loss: 0.5754 - val_accuracy: 0.7031\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.6979 - val_loss: 0.5751 - val_accuracy: 0.7031\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.6979 - val_loss: 0.5747 - val_accuracy: 0.7031\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.6979 - val_loss: 0.5743 - val_accuracy: 0.7031\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "# SGD is stochastic gradient descent\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "#y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1=pd.DataFrame(y_pred_prob_nn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1=np.array(y_pred_class_nn_1[0].apply(lambda x : 0 if x<0.5 else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1=y_pred_class_nn_1.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4613693 ],\n",
       "       [0.51292455],\n",
       "       [0.3384255 ],\n",
       "       [0.24746878],\n",
       "       [0.2781613 ],\n",
       "       [0.4702617 ],\n",
       "       [0.21889645],\n",
       "       [0.31960782],\n",
       "       [0.6152793 ],\n",
       "       [0.29782355]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.703\n",
      "roc-auc is 0.759\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.6979 - val_loss: 0.5739 - val_accuracy: 0.7031\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.6997 - val_loss: 0.5735 - val_accuracy: 0.7031\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.6997 - val_loss: 0.5731 - val_accuracy: 0.7031\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7014 - val_loss: 0.5728 - val_accuracy: 0.7031\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7031 - val_loss: 0.5724 - val_accuracy: 0.7031\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7031 - val_loss: 0.5720 - val_accuracy: 0.6979\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7031 - val_loss: 0.5716 - val_accuracy: 0.6979\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7049 - val_loss: 0.5713 - val_accuracy: 0.6979\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7066 - val_loss: 0.5709 - val_accuracy: 0.6979\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7066 - val_loss: 0.5705 - val_accuracy: 0.6979\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7066 - val_loss: 0.5701 - val_accuracy: 0.7031\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7066 - val_loss: 0.5698 - val_accuracy: 0.7031\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7066 - val_loss: 0.5694 - val_accuracy: 0.7031\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7066 - val_loss: 0.5690 - val_accuracy: 0.7031\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7049 - val_loss: 0.5687 - val_accuracy: 0.7031\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7066 - val_loss: 0.5683 - val_accuracy: 0.7031\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7066 - val_loss: 0.5680 - val_accuracy: 0.7031\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7083 - val_loss: 0.5676 - val_accuracy: 0.7031\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7066 - val_loss: 0.5672 - val_accuracy: 0.7031\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7101 - val_loss: 0.5669 - val_accuracy: 0.7083\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7083 - val_loss: 0.5665 - val_accuracy: 0.7083\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7118 - val_loss: 0.5662 - val_accuracy: 0.7083\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7135 - val_loss: 0.5658 - val_accuracy: 0.7083\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7135 - val_loss: 0.5655 - val_accuracy: 0.7083\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7170 - val_loss: 0.5651 - val_accuracy: 0.7083\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7188 - val_loss: 0.5648 - val_accuracy: 0.7083\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7188 - val_loss: 0.5644 - val_accuracy: 0.7083\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7188 - val_loss: 0.5641 - val_accuracy: 0.7083\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7205 - val_loss: 0.5637 - val_accuracy: 0.7135\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7188 - val_loss: 0.5634 - val_accuracy: 0.7135\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7188 - val_loss: 0.5630 - val_accuracy: 0.7135\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7188 - val_loss: 0.5627 - val_accuracy: 0.7135\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7205 - val_loss: 0.5624 - val_accuracy: 0.7135\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7205 - val_loss: 0.5620 - val_accuracy: 0.7135\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7205 - val_loss: 0.5617 - val_accuracy: 0.7135\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7222 - val_loss: 0.5614 - val_accuracy: 0.7135\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7205 - val_loss: 0.5610 - val_accuracy: 0.7083\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7240 - val_loss: 0.5607 - val_accuracy: 0.7083\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7205 - val_loss: 0.5604 - val_accuracy: 0.7083\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7222 - val_loss: 0.5600 - val_accuracy: 0.7083\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7257 - val_loss: 0.5597 - val_accuracy: 0.7083\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7240 - val_loss: 0.5594 - val_accuracy: 0.7083\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7257 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7257 - val_loss: 0.5587 - val_accuracy: 0.7083\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7274 - val_loss: 0.5584 - val_accuracy: 0.7031\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7292 - val_loss: 0.5581 - val_accuracy: 0.7031\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7292 - val_loss: 0.5578 - val_accuracy: 0.7031\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7292 - val_loss: 0.5574 - val_accuracy: 0.7083\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7309 - val_loss: 0.5571 - val_accuracy: 0.7083\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7309 - val_loss: 0.5568 - val_accuracy: 0.7031\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7309 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7309 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7309 - val_loss: 0.5559 - val_accuracy: 0.7083\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7326 - val_loss: 0.5555 - val_accuracy: 0.7083\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7344 - val_loss: 0.5552 - val_accuracy: 0.7083\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7344 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7361 - val_loss: 0.5546 - val_accuracy: 0.7083\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7378 - val_loss: 0.5543 - val_accuracy: 0.7083\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7396 - val_loss: 0.5540 - val_accuracy: 0.7083\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7378 - val_loss: 0.5537 - val_accuracy: 0.7083\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7396 - val_loss: 0.5534 - val_accuracy: 0.7083\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7413 - val_loss: 0.5531 - val_accuracy: 0.7083\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7431 - val_loss: 0.5528 - val_accuracy: 0.7083\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7431 - val_loss: 0.5525 - val_accuracy: 0.7083\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7431 - val_loss: 0.5522 - val_accuracy: 0.7083\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7431 - val_loss: 0.5519 - val_accuracy: 0.7083\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7448 - val_loss: 0.5516 - val_accuracy: 0.7083\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7465 - val_loss: 0.5513 - val_accuracy: 0.7083\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7465 - val_loss: 0.5510 - val_accuracy: 0.7083\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7465 - val_loss: 0.5507 - val_accuracy: 0.7083\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7483 - val_loss: 0.5504 - val_accuracy: 0.7083\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7483 - val_loss: 0.5501 - val_accuracy: 0.7083\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7483 - val_loss: 0.5498 - val_accuracy: 0.7083\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7483 - val_loss: 0.5496 - val_accuracy: 0.7083\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7483 - val_loss: 0.5493 - val_accuracy: 0.7083\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7483 - val_loss: 0.5490 - val_accuracy: 0.7083\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7483 - val_loss: 0.5487 - val_accuracy: 0.7083\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7483 - val_loss: 0.5484 - val_accuracy: 0.7083\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7500 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7500 - val_loss: 0.5479 - val_accuracy: 0.7135\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7135\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7517 - val_loss: 0.5473 - val_accuracy: 0.7135\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7517 - val_loss: 0.5470 - val_accuracy: 0.7135\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7517 - val_loss: 0.5467 - val_accuracy: 0.7135\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7517 - val_loss: 0.5465 - val_accuracy: 0.7135\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7535 - val_loss: 0.5462 - val_accuracy: 0.7188\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7552 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7552 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7552 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7535 - val_loss: 0.5451 - val_accuracy: 0.7188\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7552 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7552 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7552 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7552 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7569 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7569 - val_loss: 0.5435 - val_accuracy: 0.7188\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7587 - val_loss: 0.5433 - val_accuracy: 0.7240\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7622 - val_loss: 0.5430 - val_accuracy: 0.7240\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7604 - val_loss: 0.5427 - val_accuracy: 0.7240\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7240\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7622 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7622 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7622 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7622 - val_loss: 0.5412 - val_accuracy: 0.7240\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7604 - val_loss: 0.5410 - val_accuracy: 0.7240\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7604 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7604 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7604 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7604 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7604 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7604 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7604 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7604 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7604 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7604 - val_loss: 0.5385 - val_accuracy: 0.7344\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7604 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7604 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7604 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7604 - val_loss: 0.5376 - val_accuracy: 0.7344\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7604 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7622 - val_loss: 0.5371 - val_accuracy: 0.7344\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7604 - val_loss: 0.5369 - val_accuracy: 0.7344\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7604 - val_loss: 0.5367 - val_accuracy: 0.7344\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7622 - val_loss: 0.5364 - val_accuracy: 0.7344\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7622 - val_loss: 0.5362 - val_accuracy: 0.7344\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7622 - val_loss: 0.5360 - val_accuracy: 0.7344\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7622 - val_loss: 0.5357 - val_accuracy: 0.7344\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7622 - val_loss: 0.5355 - val_accuracy: 0.7344\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7622 - val_loss: 0.5353 - val_accuracy: 0.7344\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7604 - val_loss: 0.5351 - val_accuracy: 0.7344\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7604 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7622 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7604 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7622 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7622 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7622 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7639 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7639 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7639 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7639 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7639 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7639 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7639 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7622 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7639 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7639 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7639 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7639 - val_loss: 0.5312 - val_accuracy: 0.7396\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7639 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7639 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7656 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7639 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7639 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7622 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7656 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7622 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7622 - val_loss: 0.5294 - val_accuracy: 0.7448\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7604 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7604 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7604 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5281 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7622 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7622 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7622 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7622 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5270 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7622 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7622 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7622 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7622 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7622 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7639 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7639 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7639 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7639 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7656 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7639 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7656 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7656 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7639 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7656 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7639 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7639 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7656 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7656 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7656 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7656 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7656 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7656 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7656 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7656 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7674 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7674 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7674 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7674 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7674 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7691 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7691 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7691 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7691 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7691 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7691 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7691 - val_loss: 0.5179 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7691 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7691 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7691 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7691 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7691 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7691 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7708 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7708 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7726 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7726 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7726 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7726 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7726 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7726 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7726 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7708 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7708 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7708 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7708 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7691 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7691 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7691 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7691 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7691 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7691 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7743 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7743 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7726 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7743 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7743 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7743 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7743 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7726 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7760 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7760 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7760 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7760 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7760 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7743 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7743 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7743 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7743 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7743 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7743 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7778 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7778 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7778 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7778 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7778 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7778 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7778 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7778 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7778 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7778 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7778 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7778 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7778 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7778 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7778 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7778 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7778 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7778 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7778 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7778 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7795 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7795 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7795 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7778 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7812 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7830 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7830 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7812 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7830 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7812 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7812 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7812 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4957 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7795 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7795 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x187401da3a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6821 - accuracy: 0.6024 - val_loss: 0.6808 - val_accuracy: 0.5729\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6181 - val_loss: 0.6751 - val_accuracy: 0.6042\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6302 - val_loss: 0.6697 - val_accuracy: 0.6406\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.6354 - val_loss: 0.6646 - val_accuracy: 0.6562\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6562 - val_loss: 0.6599 - val_accuracy: 0.6615\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6649 - val_loss: 0.6554 - val_accuracy: 0.6771\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6649 - val_loss: 0.6511 - val_accuracy: 0.6771\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6719 - val_loss: 0.6471 - val_accuracy: 0.6823\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6736 - val_loss: 0.6433 - val_accuracy: 0.6719\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6771 - val_loss: 0.6398 - val_accuracy: 0.6719\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6684 - val_loss: 0.6364 - val_accuracy: 0.6719\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6736 - val_loss: 0.6333 - val_accuracy: 0.6875\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6719 - val_loss: 0.6303 - val_accuracy: 0.6771\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6788 - val_loss: 0.6273 - val_accuracy: 0.6667\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6840 - val_loss: 0.6246 - val_accuracy: 0.6667\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6840 - val_loss: 0.6219 - val_accuracy: 0.6615\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6806 - val_loss: 0.6194 - val_accuracy: 0.6458\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6823 - val_loss: 0.6170 - val_accuracy: 0.6458\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6823 - val_loss: 0.6147 - val_accuracy: 0.6302\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6771 - val_loss: 0.6124 - val_accuracy: 0.6354\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6788 - val_loss: 0.6102 - val_accuracy: 0.6406\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6719 - val_loss: 0.6081 - val_accuracy: 0.6406\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6684 - val_loss: 0.6060 - val_accuracy: 0.6406\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.6684 - val_loss: 0.6040 - val_accuracy: 0.6406\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.6684 - val_loss: 0.6020 - val_accuracy: 0.6406\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6719 - val_loss: 0.6002 - val_accuracy: 0.6458\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6719 - val_loss: 0.5984 - val_accuracy: 0.6458\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6719 - val_loss: 0.5967 - val_accuracy: 0.6458\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6701 - val_loss: 0.5950 - val_accuracy: 0.6458\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.6719 - val_loss: 0.5934 - val_accuracy: 0.6458\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6719 - val_loss: 0.5918 - val_accuracy: 0.6458\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6701 - val_loss: 0.5903 - val_accuracy: 0.6458\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6701 - val_loss: 0.5889 - val_accuracy: 0.6458\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6719 - val_loss: 0.5874 - val_accuracy: 0.6458\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6719 - val_loss: 0.5860 - val_accuracy: 0.6458\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6719 - val_loss: 0.5847 - val_accuracy: 0.6458\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.6753 - val_loss: 0.5834 - val_accuracy: 0.6458\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.6753 - val_loss: 0.5822 - val_accuracy: 0.6458\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.6771 - val_loss: 0.5810 - val_accuracy: 0.6458\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6806 - val_loss: 0.5798 - val_accuracy: 0.6458\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5709 - accuracy: 0.6806 - val_loss: 0.5786 - val_accuracy: 0.6458\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6823 - val_loss: 0.5775 - val_accuracy: 0.6458\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.6806 - val_loss: 0.5764 - val_accuracy: 0.6458\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.6858 - val_loss: 0.5754 - val_accuracy: 0.6510\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.6823 - val_loss: 0.5744 - val_accuracy: 0.6510\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.6840 - val_loss: 0.5734 - val_accuracy: 0.6510\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.6840 - val_loss: 0.5725 - val_accuracy: 0.6510\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.6840 - val_loss: 0.5715 - val_accuracy: 0.6562\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.6875 - val_loss: 0.5706 - val_accuracy: 0.6615\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.6875 - val_loss: 0.5697 - val_accuracy: 0.6615\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.6875 - val_loss: 0.5689 - val_accuracy: 0.6615\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.6910 - val_loss: 0.5680 - val_accuracy: 0.6615\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.6910 - val_loss: 0.5672 - val_accuracy: 0.6615\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.6892 - val_loss: 0.5664 - val_accuracy: 0.6615\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.6892 - val_loss: 0.5656 - val_accuracy: 0.6615\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.6875 - val_loss: 0.5648 - val_accuracy: 0.6615\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.6875 - val_loss: 0.5641 - val_accuracy: 0.6667\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.6875 - val_loss: 0.5633 - val_accuracy: 0.6667\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.6875 - val_loss: 0.5625 - val_accuracy: 0.6719\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.6892 - val_loss: 0.5618 - val_accuracy: 0.6719\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.6910 - val_loss: 0.5610 - val_accuracy: 0.6719\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.6910 - val_loss: 0.5603 - val_accuracy: 0.6771\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.6927 - val_loss: 0.5595 - val_accuracy: 0.6771\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.6910 - val_loss: 0.5588 - val_accuracy: 0.6927\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.6910 - val_loss: 0.5581 - val_accuracy: 0.6927\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.6910 - val_loss: 0.5574 - val_accuracy: 0.6927\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.6910 - val_loss: 0.5567 - val_accuracy: 0.6875\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.6910 - val_loss: 0.5561 - val_accuracy: 0.6875\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.6927 - val_loss: 0.5554 - val_accuracy: 0.6875\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.6927 - val_loss: 0.5547 - val_accuracy: 0.6927\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.6979 - val_loss: 0.5540 - val_accuracy: 0.6927\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.6979 - val_loss: 0.5534 - val_accuracy: 0.6927\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.6962 - val_loss: 0.5527 - val_accuracy: 0.7031\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.6962 - val_loss: 0.5521 - val_accuracy: 0.7031\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.6962 - val_loss: 0.5514 - val_accuracy: 0.7031\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.6962 - val_loss: 0.5508 - val_accuracy: 0.7031\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7014 - val_loss: 0.5502 - val_accuracy: 0.7031\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7031 - val_loss: 0.5495 - val_accuracy: 0.7031\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7014 - val_loss: 0.5489 - val_accuracy: 0.7031\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7014 - val_loss: 0.5483 - val_accuracy: 0.7031\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.6997 - val_loss: 0.5477 - val_accuracy: 0.7031\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.6979 - val_loss: 0.5472 - val_accuracy: 0.7031\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.6997 - val_loss: 0.5466 - val_accuracy: 0.7083\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.6979 - val_loss: 0.5461 - val_accuracy: 0.7135\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.6979 - val_loss: 0.5456 - val_accuracy: 0.7083\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7031 - val_loss: 0.5451 - val_accuracy: 0.7083\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7031 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7066 - val_loss: 0.5441 - val_accuracy: 0.7083\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7066 - val_loss: 0.5436 - val_accuracy: 0.7083\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7066 - val_loss: 0.5431 - val_accuracy: 0.7135\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7049 - val_loss: 0.5426 - val_accuracy: 0.7135\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7049 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7049 - val_loss: 0.5417 - val_accuracy: 0.7188\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7066 - val_loss: 0.5413 - val_accuracy: 0.7188\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7083 - val_loss: 0.5408 - val_accuracy: 0.7188\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7083 - val_loss: 0.5404 - val_accuracy: 0.7240\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7101 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7066 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7083 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7066 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7066 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7066 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7083 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7083 - val_loss: 0.5372 - val_accuracy: 0.7135\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7083 - val_loss: 0.5368 - val_accuracy: 0.7135\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7083 - val_loss: 0.5364 - val_accuracy: 0.7135\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7083 - val_loss: 0.5360 - val_accuracy: 0.7135\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7083 - val_loss: 0.5357 - val_accuracy: 0.7135\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7083 - val_loss: 0.5353 - val_accuracy: 0.7135\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7066 - val_loss: 0.5350 - val_accuracy: 0.7135\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7066 - val_loss: 0.5346 - val_accuracy: 0.7083\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7066 - val_loss: 0.5343 - val_accuracy: 0.7083\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7049 - val_loss: 0.5339 - val_accuracy: 0.7083\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7049 - val_loss: 0.5336 - val_accuracy: 0.7083\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7049 - val_loss: 0.5333 - val_accuracy: 0.7135\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7083 - val_loss: 0.5329 - val_accuracy: 0.7188\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7083 - val_loss: 0.5326 - val_accuracy: 0.7188\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7101 - val_loss: 0.5323 - val_accuracy: 0.7188\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7101 - val_loss: 0.5320 - val_accuracy: 0.7188\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7101 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7101 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7101 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7101 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7101 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7118 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7118 - val_loss: 0.5299 - val_accuracy: 0.7135\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7135 - val_loss: 0.5296 - val_accuracy: 0.7135\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7135 - val_loss: 0.5293 - val_accuracy: 0.7135\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7135 - val_loss: 0.5290 - val_accuracy: 0.7135\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7135 - val_loss: 0.5287 - val_accuracy: 0.7135\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7118 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7135 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7135 - val_loss: 0.5280 - val_accuracy: 0.7292\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7153 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7153 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7153 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7135 - val_loss: 0.5270 - val_accuracy: 0.7292\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7153 - val_loss: 0.5268 - val_accuracy: 0.7292\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7135 - val_loss: 0.5265 - val_accuracy: 0.7292\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7153 - val_loss: 0.5263 - val_accuracy: 0.7292\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7170 - val_loss: 0.5261 - val_accuracy: 0.7292\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7170 - val_loss: 0.5259 - val_accuracy: 0.7292\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7170 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7188 - val_loss: 0.5255 - val_accuracy: 0.7292\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7205 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7240 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7274 - val_loss: 0.5249 - val_accuracy: 0.7240\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7292 - val_loss: 0.5247 - val_accuracy: 0.7292\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7292 - val_loss: 0.5245 - val_accuracy: 0.7292\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7326 - val_loss: 0.5243 - val_accuracy: 0.7292\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7326 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7344 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7344 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7344 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7465 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7587 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7587 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7587 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7587 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7587 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7587 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7569 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7569 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7448\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7569 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7569 - val_loss: 0.5209 - val_accuracy: 0.7448\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7569 - val_loss: 0.5207 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7569 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7569 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7569 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7569 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7587 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7569 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7587 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7587 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7587 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7587 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7604 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7622 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7622 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5186 - val_accuracy: 0.7448\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7604 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7604 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7604 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7587 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7604 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7604 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7587 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7604 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7587 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7604 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7604 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7604 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7622 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7604 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7604 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7604 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7604 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7604 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7587 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7604 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7604 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7604 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7604 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7587 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7587 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7587 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7587 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7587 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7587 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7622 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7622 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7622 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7622 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7622 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7622 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7656 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7639 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7674 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7656 - val_loss: 0.5151 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7656 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7708 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7708 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7708 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7708 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7726 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7708 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.5141 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7691 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7674 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7674 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7674 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7674 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7708 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7240\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7292\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7847 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7917 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7917 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7917 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7917 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7917 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7934 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7917 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7917 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.5166 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7951 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7934 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7934 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7951 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7934 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7934 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7934 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7934 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7934 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7951 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7951 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7951 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7951 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7951 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7951 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.5186 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7951 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7951 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7951 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7969 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7969 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7969 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8003 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8003 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8003 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8003 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8003 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8003 - val_loss: 0.5208 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8003 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8003 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7986 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8003 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8003 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8003 - val_loss: 0.5228 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8003 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8003 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8003 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5250 - val_accuracy: 0.7604\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7604\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8003 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8021 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5257 - val_accuracy: 0.7604\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8021 - val_loss: 0.5259 - val_accuracy: 0.7604\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8003 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8003 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5276 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8003 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8003 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5295 - val_accuracy: 0.7604\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5296 - val_accuracy: 0.7604\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5296 - val_accuracy: 0.7604\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5297 - val_accuracy: 0.7604\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5298 - val_accuracy: 0.7604\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5299 - val_accuracy: 0.7604\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5299 - val_accuracy: 0.7604\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5299 - val_accuracy: 0.7604\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5301 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7951 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7951 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7951 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7951 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5320 - val_accuracy: 0.7552\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.5320 - val_accuracy: 0.7552\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5323 - val_accuracy: 0.7552\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5323 - val_accuracy: 0.7552\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.5324 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5325 - val_accuracy: 0.7552\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5325 - val_accuracy: 0.7552\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5326 - val_accuracy: 0.7552\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5326 - val_accuracy: 0.7552\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.5327 - val_accuracy: 0.7552\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5327 - val_accuracy: 0.7552\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5330 - val_accuracy: 0.7552\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5330 - val_accuracy: 0.7552\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5330 - val_accuracy: 0.7552\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5333 - val_accuracy: 0.7604\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5337 - val_accuracy: 0.7604\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5337 - val_accuracy: 0.7604\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5339 - val_accuracy: 0.7604\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5339 - val_accuracy: 0.7604\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5342 - val_accuracy: 0.7604\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.5342 - val_accuracy: 0.7604\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5343 - val_accuracy: 0.7604\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5343 - val_accuracy: 0.7604\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7604\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7604\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7969 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7604\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7604\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5352 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5352 - val_accuracy: 0.7604\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5353 - val_accuracy: 0.7604\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5353 - val_accuracy: 0.7604\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7604\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7604\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5358 - val_accuracy: 0.7604\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5358 - val_accuracy: 0.7604\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5369 - val_accuracy: 0.7604\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5369 - val_accuracy: 0.7604\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.5369 - val_accuracy: 0.7604\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5373 - val_accuracy: 0.7604\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5373 - val_accuracy: 0.7604\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5373 - val_accuracy: 0.7604\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.5375 - val_accuracy: 0.7604\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5375 - val_accuracy: 0.7604\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.5376 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5377 - val_accuracy: 0.7604\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5377 - val_accuracy: 0.7604\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.5378 - val_accuracy: 0.7604\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5378 - val_accuracy: 0.7604\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.5378 - val_accuracy: 0.7604\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7604\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5391 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5391 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5391 - val_accuracy: 0.7604\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5392 - val_accuracy: 0.7604\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5392 - val_accuracy: 0.7604\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5392 - val_accuracy: 0.7604\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5393 - val_accuracy: 0.7604\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5393 - val_accuracy: 0.7604\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5393 - val_accuracy: 0.7604\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5394 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5396 - val_accuracy: 0.7604\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5396 - val_accuracy: 0.7604\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5396 - val_accuracy: 0.7604\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5398 - val_accuracy: 0.7604\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5398 - val_accuracy: 0.7604\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5398 - val_accuracy: 0.7604\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5399 - val_accuracy: 0.7604\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5399 - val_accuracy: 0.7604\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5399 - val_accuracy: 0.7604\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7604\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7986 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7986 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5408 - val_accuracy: 0.7604\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.5408 - val_accuracy: 0.7604\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5408 - val_accuracy: 0.7604\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.5410 - val_accuracy: 0.7604\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.5410 - val_accuracy: 0.7604\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.5410 - val_accuracy: 0.7604\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.5410 - val_accuracy: 0.7604\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.5411 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5411 - val_accuracy: 0.7604\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5411 - val_accuracy: 0.7604\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5411 - val_accuracy: 0.7604\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.5413 - val_accuracy: 0.7604\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5413 - val_accuracy: 0.7604\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.5413 - val_accuracy: 0.7604\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5414 - val_accuracy: 0.7604\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5414 - val_accuracy: 0.7604\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5414 - val_accuracy: 0.7604\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5414 - val_accuracy: 0.7604\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5415 - val_accuracy: 0.7604\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8003 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8003 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8003 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8003 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8003 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8003 - val_loss: 0.5429 - val_accuracy: 0.7604\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8003 - val_loss: 0.5429 - val_accuracy: 0.7604\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8003 - val_loss: 0.5430 - val_accuracy: 0.7604\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8003 - val_loss: 0.5430 - val_accuracy: 0.7604\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5430 - val_accuracy: 0.7604\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5430 - val_accuracy: 0.7604\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5431 - val_accuracy: 0.7604\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8003 - val_loss: 0.5431 - val_accuracy: 0.7604\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8003 - val_loss: 0.5431 - val_accuracy: 0.7604\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5432 - val_accuracy: 0.7604\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5432 - val_accuracy: 0.7604\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5432 - val_accuracy: 0.7604\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5432 - val_accuracy: 0.7604\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5433 - val_accuracy: 0.7604\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8003 - val_loss: 0.5434 - val_accuracy: 0.7604\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5434 - val_accuracy: 0.7604\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8003 - val_loss: 0.5434 - val_accuracy: 0.7604\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8003 - val_loss: 0.5434 - val_accuracy: 0.7604\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8003 - val_loss: 0.5435 - val_accuracy: 0.7604\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8003 - val_loss: 0.5435 - val_accuracy: 0.7604\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8003 - val_loss: 0.5435 - val_accuracy: 0.7604\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8003 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8003 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8021 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8003 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8003 - val_loss: 0.5439 - val_accuracy: 0.7604\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7604\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7604\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7604\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8003 - val_loss: 0.5439 - val_accuracy: 0.7604\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5439 - val_accuracy: 0.7604\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7986 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7986 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8003 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8003 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8003 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8003 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5481 - val_accuracy: 0.7500\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8038 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5484 - val_accuracy: 0.7500\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8038 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5491 - val_accuracy: 0.7500\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.5491 - val_accuracy: 0.7500\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5491 - val_accuracy: 0.7500\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8038 - val_loss: 0.5491 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n",
      "\n",
      "accuracy is 0.750\n",
      "roc-auc is 0.795\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "y_pred_class_nn_2=pd.DataFrame(y_pred_prob_nn_2)\n",
    "y_pred_class_nn_2=np.array(y_pred_class_nn_2[0].apply(lambda x : 0 if x<0.5 else 1))\n",
    "y_pred_class_nn_2=y_pred_class_nn_2.reshape(-1,1)\n",
    "\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
